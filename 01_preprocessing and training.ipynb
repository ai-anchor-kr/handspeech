{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce73f030-5040-4bb2-9782-a5a38a38a6e5",
   "metadata": {},
   "source": [
    "# 0. Package 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fed1b9-640a-48ed-bec8-4e0e6cb41181",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd6aba9-dc36-447e-9e23-94e471ba06bf",
   "metadata": {},
   "source": [
    "# 1. Video -> Frame 전처리\n",
    "### video_path 에 입력 비디오 경로\n",
    "### frame_path 에 전처리되어 나올 frame 경로\n",
    "### 입력받은 비디오를 center crop하여 frame별로 저장\n",
    "### 홍나실 비디오 위치 : vision@/data1/imsi\n",
    "### ** 이미 전처리 된 이미지를 사용하고 싶으면 아래 경로 참조\n",
    "### vision@/data1/dict/articulated-animation/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01afac72-318a-47b7-b984-dee87cb9c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86b7dff-d4ee-45f1-84f6-f653230e793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './data/handspeech_video/*.mp4'\n",
    "frame_path = './data/handspeech_frame'\n",
    "frame_size = 384\n",
    "SKIP_FRAME_RATE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc3a7d1-c8cd-4e83-a532-436c0269bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_list = glob.glob(f'{video_path}', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d1c03d-f966-4c46-a9fe-76812910997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/handspeech_video/covid_Real.mp4',\n",
       " './data/handspeech_video/covid_Avatar.mp4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc3ffb66-7b89-46e3-b772-7e524cc57cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:15<00:00,  7.98s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, VIDEO_PATH in enumerate(tqdm(video_list)):\n",
    "    if i < len(mp4_list)*0.95:\n",
    "        phaze = 'train'\n",
    "    else:\n",
    "        phaze = 'test'\n",
    "    fname = VIDEO_PATH.split('/')[-1].split('.mp4')[0]\n",
    "    raw_img_dir = f'{frame_path}/{phaze}/{fname}'\n",
    "    path = Path(raw_img_dir)\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    capture = cv2.VideoCapture(VIDEO_PATH)\n",
    "    SKIP_FRAME = int(capture.get(cv2.CAP_PROP_FPS) + 0.1)//SKIP_FRAME_RATE\n",
    "    w = int(capture.get(cv2. CAP_PROP_FRAME_WIDTH ))\n",
    "    h = int(capture.get(cv2. CAP_PROP_FRAME_HEIGHT ))\n",
    "    x = int((w-h)/2)\n",
    "    y = 0\n",
    "    idx = 0\n",
    "    n = 0\n",
    "    while(capture.isOpened()):\n",
    "        ret = capture.grab()\n",
    "        if ret == False:\n",
    "            break\n",
    "        if idx % SKIP_FRAME == 0:\n",
    "            ret, frame = capture.retrieve()\n",
    "            cv2.imwrite(f'{raw_img_dir}/out{n:05d}.jpg', cv2.resize(frame, (frame_size,frame_size), interpolation=cv2.INTER_AREA))\n",
    "            n += 1\n",
    "            # do something with frame\n",
    "        idx += 1\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c15e3-eb26-4261-a697-1f3e0fc80f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a69ac8-d8c5-4921-90a3-90ddfa7f43e5",
   "metadata": {},
   "source": [
    "# 2. Config 생성\n",
    "### ./config/handspeech 를 참고하여 생성하되, dataset_params -> root_dir 은 위의 frame_path를 입력해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d0e52-b453-4ecc-a562-5f8d05ad2019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13c69f5-20f8-4e02-9ca2-8b2356eba919",
   "metadata": {},
   "source": [
    "# 3. Main 모델 학습\n",
    "### 2.에서 생성한 config path를 입력 후 실행\n",
    "### 학습 중간 결과 및 checkpoint 가 ./log 밑에 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8adb5-7603-4474-978f-f9d6e08a2ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py --config config/handspeech.yaml --device_ids 0,1,2,3,4,5,6,7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9a13f-f384-4aa3-b65a-484fedb6bb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "346a2d9e-751c-4f6e-be24-2c1d6c6637e2",
   "metadata": {},
   "source": [
    "# 4. AVD 모델 학습\n",
    "### 3. 에서 훈련되어 나온 checkpoint의 경로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91233e-ed9f-4874-ac60-534d99684113",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run.py -checkpoint {PATH-TO-MODEL.pth} --config config/handspeech.yaml --device_ids 0,1,2,3,4,5,6,7 --mode train_avd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
